{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a192a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfcb0b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGEIR</th>\n",
       "      <th>TC</th>\n",
       "      <th>HDL</th>\n",
       "      <th>SMOKE_</th>\n",
       "      <th>BPMED</th>\n",
       "      <th>DIAB_01</th>\n",
       "      <th>RISK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>236</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>260</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>187</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>216</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  AGEIR   TC  HDL  SMOKE_  BPMED  DIAB_01  RISK\n",
       "0    1     48  236   66       0      1        0   1.1\n",
       "1    0     48  260   51       0      1        1   7.0\n",
       "2    0     44  187   49       1      1        0   7.0\n",
       "3    1     42  216   57       1      1        0   0.4\n",
       "4    1     56  156   42       0      1        0   2.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cardio_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09beb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('RISK', axis=1)\n",
    "y = data['RISK'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d790eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y = np.reshape(y, (-1, 1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# scaler for X\n",
    "x_scaler = MinMaxScaler()\n",
    "x_train = x_scaler.fit_transform(x_train)\n",
    "x_test  = x_scaler.transform(x_test)\n",
    "\n",
    "# scaler for y\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_test  = y_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f14b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Ai\\Deep_Learning\\regression\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras.models as sequential\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = sequential.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(7,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]   # or use \"mse\" too\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46efb5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,393</span> (44.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,393\u001b[0m (44.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,393</span> (44.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,393\u001b[0m (44.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb02fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0754 - val_loss: 0.0046 - val_mae: 0.0408\n",
      "Epoch 2/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0386\n",
      "Epoch 3/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0449 - val_loss: 0.0041 - val_mae: 0.0374\n",
      "Epoch 4/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0450 - val_loss: 0.0038 - val_mae: 0.0382\n",
      "Epoch 5/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0048 - mae: 0.0433 - val_loss: 0.0038 - val_mae: 0.0371\n",
      "Epoch 6/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0428 - val_loss: 0.0039 - val_mae: 0.0370\n",
      "Epoch 7/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0427 - val_loss: 0.0057 - val_mae: 0.0446\n",
      "Epoch 8/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0426 - val_loss: 0.0035 - val_mae: 0.0362\n",
      "Epoch 9/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0409 - val_loss: 0.0035 - val_mae: 0.0377\n",
      "Epoch 10/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0043 - mae: 0.0416 - val_loss: 0.0037 - val_mae: 0.0356\n",
      "Epoch 11/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0040 - mae: 0.0403 - val_loss: 0.0039 - val_mae: 0.0363\n",
      "Epoch 12/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0405 - val_loss: 0.0035 - val_mae: 0.0349\n",
      "Epoch 13/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0040 - mae: 0.0400 - val_loss: 0.0035 - val_mae: 0.0349\n",
      "Epoch 14/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0400 - val_loss: 0.0035 - val_mae: 0.0355\n",
      "Epoch 15/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0404 - val_loss: 0.0042 - val_mae: 0.0385\n",
      "Epoch 16/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0399 - val_loss: 0.0037 - val_mae: 0.0383\n",
      "Epoch 17/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0399 - val_loss: 0.0041 - val_mae: 0.0368\n",
      "Epoch 18/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0404 - val_loss: 0.0051 - val_mae: 0.0405\n",
      "Epoch 19/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0392 - val_loss: 0.0036 - val_mae: 0.0360\n",
      "Epoch 20/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0397 - val_loss: 0.0034 - val_mae: 0.0343\n",
      "Epoch 21/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0393 - val_loss: 0.0034 - val_mae: 0.0356\n",
      "Epoch 22/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0392 - val_loss: 0.0036 - val_mae: 0.0343\n",
      "Epoch 23/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0393 - val_loss: 0.0034 - val_mae: 0.0346\n",
      "Epoch 24/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0395 - val_loss: 0.0038 - val_mae: 0.0367\n",
      "Epoch 25/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0387 - val_loss: 0.0040 - val_mae: 0.0388\n",
      "Epoch 26/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0388 - val_loss: 0.0038 - val_mae: 0.0352\n",
      "Epoch 27/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0390 - val_loss: 0.0035 - val_mae: 0.0343\n",
      "Epoch 28/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0350\n",
      "Epoch 29/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0386 - val_loss: 0.0033 - val_mae: 0.0336\n",
      "Epoch 30/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0379 - val_loss: 0.0034 - val_mae: 0.0350\n",
      "Epoch 31/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0387 - val_loss: 0.0035 - val_mae: 0.0368\n",
      "Epoch 32/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0402 - val_loss: 0.0035 - val_mae: 0.0346\n",
      "Epoch 33/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0382 - val_loss: 0.0034 - val_mae: 0.0349\n",
      "Epoch 34/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0035 - mae: 0.0382 - val_loss: 0.0038 - val_mae: 0.0352\n",
      "Epoch 35/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0385 - val_loss: 0.0034 - val_mae: 0.0390\n",
      "Epoch 36/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0365\n",
      "Epoch 37/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0380 - val_loss: 0.0034 - val_mae: 0.0349\n",
      "Epoch 38/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0380 - val_loss: 0.0035 - val_mae: 0.0358\n",
      "Epoch 39/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 0.0037 - val_mae: 0.0372\n",
      "Epoch 40/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0390 - val_loss: 0.0033 - val_mae: 0.0366\n",
      "Epoch 41/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0035 - mae: 0.0383 - val_loss: 0.0033 - val_mae: 0.0345\n",
      "Epoch 42/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0378 - val_loss: 0.0036 - val_mae: 0.0365\n",
      "Epoch 43/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0377 - val_loss: 0.0035 - val_mae: 0.0346\n",
      "Epoch 44/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0379 - val_loss: 0.0033 - val_mae: 0.0372\n",
      "Epoch 45/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0377 - val_loss: 0.0035 - val_mae: 0.0360\n",
      "Epoch 46/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 0.0041 - val_mae: 0.0368\n",
      "Epoch 47/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0360\n",
      "Epoch 48/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0376 - val_loss: 0.0039 - val_mae: 0.0361\n",
      "Epoch 49/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0377 - val_loss: 0.0040 - val_mae: 0.0373\n",
      "Epoch 50/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0371 - val_loss: 0.0040 - val_mae: 0.0378\n",
      "Epoch 51/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0370 - val_loss: 0.0037 - val_mae: 0.0352\n",
      "Epoch 52/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0373 - val_loss: 0.0035 - val_mae: 0.0347\n",
      "Epoch 53/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0378 - val_loss: 0.0033 - val_mae: 0.0364\n",
      "Epoch 54/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0374 - val_loss: 0.0038 - val_mae: 0.0371\n",
      "Epoch 55/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0381 - val_loss: 0.0038 - val_mae: 0.0363\n",
      "Epoch 56/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0341\n",
      "Epoch 57/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0375 - val_loss: 0.0034 - val_mae: 0.0341\n",
      "Epoch 58/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0381 - val_loss: 0.0033 - val_mae: 0.0347\n",
      "Epoch 59/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - val_loss: 0.0034 - val_mae: 0.0365\n",
      "Epoch 60/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - val_loss: 0.0036 - val_mae: 0.0353\n",
      "Epoch 61/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0372 - val_loss: 0.0034 - val_mae: 0.0359\n",
      "Epoch 62/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0033 - val_mae: 0.0362\n",
      "Epoch 63/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0372 - val_loss: 0.0041 - val_mae: 0.0358\n",
      "Epoch 64/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0036 - val_mae: 0.0359\n",
      "Epoch 65/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0379 - val_loss: 0.0036 - val_mae: 0.0355\n",
      "Epoch 66/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0355\n",
      "Epoch 67/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0371 - val_loss: 0.0035 - val_mae: 0.0347\n",
      "Epoch 68/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0377 - val_loss: 0.0035 - val_mae: 0.0348\n",
      "Epoch 69/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0034 - val_mae: 0.0376\n",
      "Epoch 70/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0368\n",
      "Epoch 71/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0040 - val_mae: 0.0360\n",
      "Epoch 72/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0372 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 73/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0366 - val_loss: 0.0034 - val_mae: 0.0370\n",
      "Epoch 74/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0033 - val_mae: 0.0361\n",
      "Epoch 75/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0370 - val_loss: 0.0035 - val_mae: 0.0379\n",
      "Epoch 76/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0035 - val_mae: 0.0361\n",
      "Epoch 77/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0366 - val_loss: 0.0034 - val_mae: 0.0357\n",
      "Epoch 78/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0372 - val_loss: 0.0034 - val_mae: 0.0341\n",
      "Epoch 79/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0363\n",
      "Epoch 80/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0367 - val_loss: 0.0034 - val_mae: 0.0352\n",
      "Epoch 81/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0367 - val_loss: 0.0037 - val_mae: 0.0381\n",
      "Epoch 82/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0361 - val_loss: 0.0033 - val_mae: 0.0368\n",
      "Epoch 83/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0366 - val_loss: 0.0035 - val_mae: 0.0351\n",
      "Epoch 84/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0034 - val_mae: 0.0378\n",
      "Epoch 85/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0033 - val_mae: 0.0347\n",
      "Epoch 86/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0369 - val_loss: 0.0035 - val_mae: 0.0366\n",
      "Epoch 87/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0364 - val_loss: 0.0036 - val_mae: 0.0375\n",
      "Epoch 88/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0374 - val_loss: 0.0034 - val_mae: 0.0356\n",
      "Epoch 89/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0036 - val_mae: 0.0359\n",
      "Epoch 90/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0390\n",
      "Epoch 91/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0365 - val_loss: 0.0037 - val_mae: 0.0355\n",
      "Epoch 92/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0038 - val_mae: 0.0372\n",
      "Epoch 93/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0034 - val_mae: 0.0347\n",
      "Epoch 94/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0034 - val_mae: 0.0346\n",
      "Epoch 95/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0033 - val_mae: 0.0361\n",
      "Epoch 96/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0035 - val_mae: 0.0368\n",
      "Epoch 97/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0039 - val_mae: 0.0405\n",
      "Epoch 98/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0035 - val_mae: 0.0373\n",
      "Epoch 99/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0036 - val_mae: 0.0348\n",
      "Epoch 100/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0345\n",
      "Epoch 101/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0339\n",
      "Epoch 102/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0033 - val_mae: 0.0372\n",
      "Epoch 103/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0037 - val_mae: 0.0359\n",
      "Epoch 104/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0359\n",
      "Epoch 105/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0034 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0356\n",
      "Epoch 106/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0034 - val_mae: 0.0370\n",
      "Epoch 107/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0366 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 108/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0035 - val_mae: 0.0380\n",
      "Epoch 109/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0034 - val_mae: 0.0368\n",
      "Epoch 110/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0035 - val_mae: 0.0351\n",
      "Epoch 111/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0034 - val_mae: 0.0350\n",
      "Epoch 112/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0034 - val_mae: 0.0338\n",
      "Epoch 113/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0033 - val_mae: 0.0344\n",
      "Epoch 114/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0033 - val_mae: 0.0358\n",
      "Epoch 115/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0035 - val_mae: 0.0355\n",
      "Epoch 116/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0034 - val_mae: 0.0361\n",
      "Epoch 117/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0033 - val_mae: 0.0364\n",
      "Epoch 118/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0363 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 119/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0035 - val_mae: 0.0350\n",
      "Epoch 120/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0035 - val_mae: 0.0372\n",
      "Epoch 121/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0360 - val_loss: 0.0037 - val_mae: 0.0374\n",
      "Epoch 122/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0364 - val_loss: 0.0034 - val_mae: 0.0364\n",
      "Epoch 123/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0034 - val_mae: 0.0367\n",
      "Epoch 124/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0036 - val_mae: 0.0350\n",
      "Epoch 125/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0039 - val_mae: 0.0396\n",
      "Epoch 126/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0368 - val_loss: 0.0040 - val_mae: 0.0381\n",
      "Epoch 127/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0366 - val_loss: 0.0036 - val_mae: 0.0372\n",
      "Epoch 128/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 129/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0366 - val_loss: 0.0033 - val_mae: 0.0334\n",
      "Epoch 130/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0365 - val_loss: 0.0034 - val_mae: 0.0364\n",
      "Epoch 131/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0034 - val_mae: 0.0358\n",
      "Epoch 132/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0375\n",
      "Epoch 133/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0362\n",
      "Epoch 134/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0359 - val_loss: 0.0034 - val_mae: 0.0345\n",
      "Epoch 135/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0359 - val_loss: 0.0033 - val_mae: 0.0385\n",
      "Epoch 136/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0033 - val_mae: 0.0335\n",
      "Epoch 137/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0032 - val_mae: 0.0337\n",
      "Epoch 138/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0037 - val_mae: 0.0365\n",
      "Epoch 139/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0360 - val_loss: 0.0036 - val_mae: 0.0357\n",
      "Epoch 140/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0036 - val_mae: 0.0381\n",
      "Epoch 141/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0036 - val_mae: 0.0354\n",
      "Epoch 142/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0363 - val_loss: 0.0034 - val_mae: 0.0374\n",
      "Epoch 143/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0036 - val_mae: 0.0349\n",
      "Epoch 144/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0033 - val_mae: 0.0366\n",
      "Epoch 145/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0037 - val_mae: 0.0355\n",
      "Epoch 146/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0033 - val_mae: 0.0345\n",
      "Epoch 147/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0370\n",
      "Epoch 148/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0034 - val_mae: 0.0345\n",
      "Epoch 149/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0033 - val_mae: 0.0362\n",
      "Epoch 150/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0039 - val_mae: 0.0363\n",
      "Epoch 151/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0035 - val_mae: 0.0363\n",
      "Epoch 152/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0376\n",
      "Epoch 153/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0365 - val_loss: 0.0034 - val_mae: 0.0370\n",
      "Epoch 154/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 155/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 0.0035 - val_mae: 0.0350\n",
      "Epoch 156/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0359 - val_loss: 0.0035 - val_mae: 0.0365\n",
      "Epoch 157/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 0.0033 - val_mae: 0.0362\n",
      "Epoch 158/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0034 - val_mae: 0.0362\n",
      "Epoch 159/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0036 - val_mae: 0.0350\n",
      "Epoch 160/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0360 - val_loss: 0.0034 - val_mae: 0.0374\n",
      "Epoch 161/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0369 - val_loss: 0.0033 - val_mae: 0.0346\n",
      "Epoch 162/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0033 - val_mae: 0.0346\n",
      "Epoch 163/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0035 - val_mae: 0.0342\n",
      "Epoch 164/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0359 - val_loss: 0.0035 - val_mae: 0.0358\n",
      "Epoch 165/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0033 - val_mae: 0.0364\n",
      "Epoch 166/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0037 - val_mae: 0.0385\n",
      "Epoch 167/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0357\n",
      "Epoch 168/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0033 - val_mae: 0.0337\n",
      "Epoch 169/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0036 - val_mae: 0.0377\n",
      "Epoch 170/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.0034 - val_mae: 0.0375\n",
      "Epoch 171/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0355 - val_loss: 0.0035 - val_mae: 0.0378\n",
      "Epoch 172/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0359 - val_loss: 0.0033 - val_mae: 0.0349\n",
      "Epoch 173/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0373\n",
      "Epoch 174/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0352 - val_loss: 0.0033 - val_mae: 0.0373\n",
      "Epoch 175/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0036 - val_mae: 0.0386\n",
      "Epoch 176/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0380\n",
      "Epoch 177/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0035 - val_mae: 0.0352\n",
      "Epoch 178/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0034 - val_mae: 0.0364\n",
      "Epoch 179/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0036 - val_mae: 0.0368\n",
      "Epoch 180/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0354 - val_loss: 0.0035 - val_mae: 0.0361\n",
      "Epoch 181/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0035 - val_mae: 0.0359\n",
      "Epoch 182/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0359 - val_loss: 0.0033 - val_mae: 0.0343\n",
      "Epoch 183/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0341\n",
      "Epoch 184/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0035 - val_mae: 0.0366\n",
      "Epoch 185/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0359 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 186/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0361\n",
      "Epoch 187/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0035 - val_mae: 0.0374\n",
      "Epoch 188/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0034 - val_mae: 0.0348\n",
      "Epoch 189/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0035 - val_mae: 0.0359\n",
      "Epoch 190/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0372\n",
      "Epoch 191/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0034 - val_mae: 0.0365\n",
      "Epoch 192/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0034 - val_mae: 0.0370\n",
      "Epoch 193/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.0034 - val_mae: 0.0352\n",
      "Epoch 194/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 195/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0033 - val_mae: 0.0364\n",
      "Epoch 196/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0353 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 197/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.0033 - val_mae: 0.0353\n",
      "Epoch 198/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0358\n",
      "Epoch 199/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0352 - val_loss: 0.0034 - val_mae: 0.0348\n",
      "Epoch 200/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0360 - val_loss: 0.0034 - val_mae: 0.0337\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91d3e7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "MSE:  0.0033766791330160266\n",
      "MAE:  0.03367206790108095\n",
      "R2:  0.8576629700542622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0066de5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2b9bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "\n",
    "class customCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predicted_result = model.predict(x_test)\n",
    "        r2 = r2_score(y_test, predicted_result)\n",
    "        print('epoch', epoch, 'R2: ', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcf57a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"models/model-{epoch:03d}.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71c53f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 1: val_loss improved from None to 0.00352, saving model to models/model-001.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0035 - val_mae: 0.0347\n",
      "Epoch 2/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0357\n",
      "Epoch 2: val_loss improved from 0.00352 to 0.00337, saving model to models/model-002.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0353\n",
      "Epoch 3/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0346\n",
      "Epoch 3: val_loss did not improve from 0.00337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0036 - val_mae: 0.0369\n",
      "Epoch 4/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0358\n",
      "Epoch 4: val_loss did not improve from 0.00337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0037 - val_mae: 0.0364\n",
      "Epoch 5/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0370\n",
      "Epoch 5: val_loss did not improve from 0.00337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 6/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0354\n",
      "Epoch 6: val_loss improved from 0.00337 to 0.00334, saving model to models/model-006.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0033 - val_mae: 0.0356\n",
      "Epoch 7/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0352\n",
      "Epoch 7: val_loss did not improve from 0.00334\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0036 - val_mae: 0.0354\n",
      "Epoch 8/200\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0361\n",
      "Epoch 8: val_loss did not improve from 0.00334\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.0035 - val_mae: 0.0356\n",
      "Epoch 9/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0353\n",
      "Epoch 9: val_loss did not improve from 0.00334\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0035 - val_mae: 0.0360\n",
      "Epoch 10/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0354\n",
      "Epoch 10: val_loss did not improve from 0.00334\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0346\n",
      "Epoch 11/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0357\n",
      "Epoch 11: val_loss improved from 0.00334 to 0.00333, saving model to models/model-011.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0033 - val_mae: 0.0368\n",
      "Epoch 12/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0348\n",
      "Epoch 12: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0353 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 13/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0349\n",
      "Epoch 13: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0353 - val_loss: 0.0034 - val_mae: 0.0350\n",
      "Epoch 14/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0343\n",
      "Epoch 14: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0359 - val_loss: 0.0034 - val_mae: 0.0347\n",
      "Epoch 15/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0349\n",
      "Epoch 15: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0034 - val_mae: 0.0357\n",
      "Epoch 16/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0368\n",
      "Epoch 16: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 17/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0359\n",
      "Epoch 17: val_loss did not improve from 0.00333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0035 - val_mae: 0.0359\n",
      "Epoch 18/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0364\n",
      "Epoch 18: val_loss improved from 0.00333 to 0.00332, saving model to models/model-018.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0033 - val_mae: 0.0351\n",
      "Epoch 19/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 19: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0035 - val_mae: 0.0355\n",
      "Epoch 20/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0347\n",
      "Epoch 20: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0349 - val_loss: 0.0034 - val_mae: 0.0364\n",
      "Epoch 21/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346\n",
      "Epoch 21: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0035 - val_mae: 0.0346\n",
      "Epoch 22/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0361\n",
      "Epoch 22: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0365\n",
      "Epoch 23/200\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0358\n",
      "Epoch 23: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0035 - val_mae: 0.0357\n",
      "Epoch 24/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 24: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0349 - val_loss: 0.0035 - val_mae: 0.0351\n",
      "Epoch 25/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0364\n",
      "Epoch 25: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0034 - val_mae: 0.0365\n",
      "Epoch 26/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0358\n",
      "Epoch 26: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0356\n",
      "Epoch 27/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0346\n",
      "Epoch 27: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0034 - val_mae: 0.0345\n",
      "Epoch 28/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0351\n",
      "Epoch 28: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.0035 - val_mae: 0.0352\n",
      "Epoch 29/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0356\n",
      "Epoch 29: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.0038 - val_mae: 0.0374\n",
      "Epoch 30/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0362\n",
      "Epoch 30: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0358 - val_loss: 0.0034 - val_mae: 0.0371\n",
      "Epoch 31/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0354\n",
      "Epoch 31: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0372\n",
      "Epoch 32/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0355\n",
      "Epoch 32: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0035 - val_mae: 0.0370\n",
      "Epoch 33/200\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0352\n",
      "Epoch 33: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0358\n",
      "Epoch 34/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0346\n",
      "Epoch 34: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0369\n",
      "Epoch 35/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0350\n",
      "Epoch 35: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0343\n",
      "Epoch 36/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0349\n",
      "Epoch 36: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0035 - val_mae: 0.0344\n",
      "Epoch 37/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0352\n",
      "Epoch 37: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.0035 - val_mae: 0.0349\n",
      "Epoch 38/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0353\n",
      "Epoch 38: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 0.0035 - val_mae: 0.0375\n",
      "Epoch 39/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0352\n",
      "Epoch 39: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0034 - val_mae: 0.0368\n",
      "Epoch 40/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0349\n",
      "Epoch 40: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0395\n",
      "Epoch 41/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0361\n",
      "Epoch 41: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0361\n",
      "Epoch 42/200\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0353\n",
      "Epoch 42: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0034 - val_mae: 0.0348\n",
      "Epoch 43/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0352\n",
      "Epoch 43: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0034 - val_mae: 0.0344\n",
      "Epoch 44/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0358\n",
      "Epoch 44: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0034 - val_mae: 0.0346\n",
      "Epoch 45/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344\n",
      "Epoch 45: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0355 - val_loss: 0.0036 - val_mae: 0.0383\n",
      "Epoch 46/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0380\n",
      "Epoch 46: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0036 - val_mae: 0.0352\n",
      "Epoch 47/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0347\n",
      "Epoch 47: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0361\n",
      "Epoch 48/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0360\n",
      "Epoch 48: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0037 - val_mae: 0.0358\n",
      "Epoch 49/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346\n",
      "Epoch 49: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0034 - val_mae: 0.0348\n",
      "Epoch 50/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0354\n",
      "Epoch 50: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.0038 - val_mae: 0.0375\n",
      "Epoch 51/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0358\n",
      "Epoch 51: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0035 - val_mae: 0.0362\n",
      "Epoch 52/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0347\n",
      "Epoch 52: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0034 - val_mae: 0.0387\n",
      "Epoch 53/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0354\n",
      "Epoch 53: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0355 - val_loss: 0.0034 - val_mae: 0.0363\n",
      "Epoch 54/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357\n",
      "Epoch 54: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0374\n",
      "Epoch 55/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0354\n",
      "Epoch 55: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0034 - val_mae: 0.0353\n",
      "Epoch 56/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0345\n",
      "Epoch 56: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0356\n",
      "Epoch 57/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0356\n",
      "Epoch 57: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0037 - val_mae: 0.0375\n",
      "Epoch 58/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0359\n",
      "Epoch 58: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0362\n",
      "Epoch 59/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0352\n",
      "Epoch 59: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0384\n",
      "Epoch 60/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0363\n",
      "Epoch 60: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0356\n",
      "Epoch 61/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0347\n",
      "Epoch 61: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0036 - val_mae: 0.0355\n",
      "Epoch 62/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0345\n",
      "Epoch 62: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0037 - val_mae: 0.0377\n",
      "Epoch 63/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0336\n",
      "Epoch 63: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0034 - val_mae: 0.0352\n",
      "Epoch 64/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0343\n",
      "Epoch 64: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0337\n",
      "Epoch 65/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0364\n",
      "Epoch 65: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0034 - val_mae: 0.0372\n",
      "Epoch 66/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0355\n",
      "Epoch 66: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0036 - val_mae: 0.0375\n",
      "Epoch 67/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0372\n",
      "Epoch 67: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 68/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0345\n",
      "Epoch 68: val_loss improved from 0.00332 to 0.00332, saving model to models/model-068.keras\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0033 - val_mae: 0.0346\n",
      "Epoch 69/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0351\n",
      "Epoch 69: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0037 - val_mae: 0.0348\n",
      "Epoch 70/200\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0342\n",
      "Epoch 70: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0362\n",
      "Epoch 71/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0343\n",
      "Epoch 71: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.0038 - val_mae: 0.0365\n",
      "Epoch 72/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0344\n",
      "Epoch 72: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0035 - val_mae: 0.0355\n",
      "Epoch 73/200\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0329\n",
      "Epoch 73: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0035 - val_mae: 0.0372\n",
      "Epoch 74/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0354\n",
      "Epoch 74: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0034 - val_mae: 0.0360\n",
      "Epoch 75/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0356\n",
      "Epoch 75: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 76/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0358\n",
      "Epoch 76: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0354 - val_loss: 0.0037 - val_mae: 0.0375\n",
      "Epoch 77/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0349\n",
      "Epoch 77: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0035 - val_mae: 0.0366\n",
      "Epoch 78/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0357\n",
      "Epoch 78: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0357\n",
      "Epoch 79/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0342\n",
      "Epoch 79: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0360\n",
      "Epoch 80/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0350\n",
      "Epoch 80: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0358\n",
      "Epoch 81/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0331\n",
      "Epoch 81: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0034 - val_mae: 0.0363\n",
      "Epoch 82/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0359\n",
      "Epoch 82: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0368\n",
      "Epoch 83/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 83: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0034 - val_mae: 0.0359\n",
      "Epoch 84/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 84: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0034 - val_mae: 0.0362\n",
      "Epoch 85/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0351\n",
      "Epoch 85: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0036 - val_mae: 0.0378\n",
      "Epoch 86/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 86: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0033 - val_mae: 0.0347\n",
      "Epoch 87/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0335\n",
      "Epoch 87: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 88/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0353\n",
      "Epoch 88: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0037 - val_mae: 0.0349\n",
      "Epoch 89/200\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0335\n",
      "Epoch 89: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0038 - val_mae: 0.0399\n",
      "Epoch 90/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0359\n",
      "Epoch 90: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0034 - val_mae: 0.0361\n",
      "Epoch 91/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0354\n",
      "Epoch 91: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0353 - val_loss: 0.0034 - val_mae: 0.0354\n",
      "Epoch 92/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0346\n",
      "Epoch 92: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0352 - val_loss: 0.0035 - val_mae: 0.0386\n",
      "Epoch 93/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0351\n",
      "Epoch 93: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.0037 - val_mae: 0.0378\n",
      "Epoch 94/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 94: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0035 - val_mae: 0.0351\n",
      "Epoch 95/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 95: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0036 - val_mae: 0.0354\n",
      "Epoch 96/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 96: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0035 - val_mae: 0.0379\n",
      "Epoch 97/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0351\n",
      "Epoch 97: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0364\n",
      "Epoch 98/200\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0336\n",
      "Epoch 98: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0355\n",
      "Epoch 99/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0355\n",
      "Epoch 99: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 100/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0352\n",
      "Epoch 100: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.0035 - val_mae: 0.0364\n",
      "Epoch 101/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347\n",
      "Epoch 101: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0040 - val_mae: 0.0367\n",
      "Epoch 102/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0342\n",
      "Epoch 102: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.0034 - val_mae: 0.0368\n",
      "Epoch 103/200\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0345\n",
      "Epoch 103: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0358\n",
      "Epoch 104/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0350\n",
      "Epoch 104: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0348 - val_loss: 0.0036 - val_mae: 0.0360\n",
      "Epoch 105/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0345\n",
      "Epoch 105: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0035 - val_mae: 0.0360\n",
      "Epoch 106/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0349\n",
      "Epoch 106: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0036 - val_mae: 0.0367\n",
      "Epoch 107/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 107: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0039 - val_mae: 0.0380\n",
      "Epoch 108/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0342\n",
      "Epoch 108: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 109/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0350\n",
      "Epoch 109: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0034 - val_mae: 0.0366\n",
      "Epoch 110/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0332\n",
      "Epoch 110: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0038 - val_mae: 0.0380\n",
      "Epoch 111/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0333\n",
      "Epoch 111: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0388\n",
      "Epoch 112/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0347\n",
      "Epoch 112: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0035 - val_mae: 0.0355\n",
      "Epoch 113/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0342\n",
      "Epoch 113: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0035 - val_mae: 0.0363\n",
      "Epoch 114/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0343\n",
      "Epoch 114: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0365\n",
      "Epoch 115/200\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0349\n",
      "Epoch 115: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0036 - val_mae: 0.0356\n",
      "Epoch 116/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0352\n",
      "Epoch 116: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0366\n",
      "Epoch 117/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0346\n",
      "Epoch 117: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 118/200\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0345\n",
      "Epoch 118: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0348 - val_loss: 0.0036 - val_mae: 0.0376\n",
      "Epoch 119/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 119: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0035 - val_mae: 0.0365\n",
      "Epoch 120/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0352\n",
      "Epoch 120: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0035 - val_mae: 0.0367\n",
      "Epoch 121/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0336\n",
      "Epoch 121: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0034 - val_mae: 0.0342\n",
      "Epoch 122/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0350\n",
      "Epoch 122: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0038 - val_mae: 0.0387\n",
      "Epoch 123/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0354\n",
      "Epoch 123: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0349 - val_loss: 0.0037 - val_mae: 0.0390\n",
      "Epoch 124/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341\n",
      "Epoch 124: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0039 - val_mae: 0.0353\n",
      "Epoch 125/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 125: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0036 - val_mae: 0.0354\n",
      "Epoch 126/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0338\n",
      "Epoch 126: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0034 - val_mae: 0.0368\n",
      "Epoch 127/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0342\n",
      "Epoch 127: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 128/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0342\n",
      "Epoch 128: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0360\n",
      "Epoch 129/200\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0335\n",
      "Epoch 129: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0034 - val_mae: 0.0347\n",
      "Epoch 130/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0347\n",
      "Epoch 130: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0036 - val_mae: 0.0382\n",
      "Epoch 131/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341\n",
      "Epoch 131: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0033 - val_mae: 0.0338\n",
      "Epoch 132/200\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0341\n",
      "Epoch 132: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 133/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0356\n",
      "Epoch 133: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0035 - val_mae: 0.0360\n",
      "Epoch 134/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0345\n",
      "Epoch 134: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0035 - val_mae: 0.0366\n",
      "Epoch 135/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0331\n",
      "Epoch 135: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0036 - val_mae: 0.0354\n",
      "Epoch 136/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 136: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0035 - val_mae: 0.0367\n",
      "Epoch 137/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0345\n",
      "Epoch 137: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0035 - val_mae: 0.0364\n",
      "Epoch 138/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0344\n",
      "Epoch 138: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0036 - val_mae: 0.0372\n",
      "Epoch 139/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0356\n",
      "Epoch 139: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0036 - val_mae: 0.0361\n",
      "Epoch 140/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 140: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 141/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0330\n",
      "Epoch 141: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0035 - val_mae: 0.0346\n",
      "Epoch 142/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0350\n",
      "Epoch 142: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0380\n",
      "Epoch 143/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0351\n",
      "Epoch 143: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0347 - val_loss: 0.0035 - val_mae: 0.0349\n",
      "Epoch 144/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 144: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0036 - val_mae: 0.0375\n",
      "Epoch 145/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0338\n",
      "Epoch 145: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0034 - val_mae: 0.0374\n",
      "Epoch 146/200\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0354\n",
      "Epoch 146: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0347 - val_loss: 0.0033 - val_mae: 0.0350\n",
      "Epoch 147/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0346\n",
      "Epoch 147: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0036 - val_mae: 0.0370\n",
      "Epoch 148/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0344\n",
      "Epoch 148: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0351 - val_loss: 0.0034 - val_mae: 0.0366\n",
      "Epoch 149/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0341\n",
      "Epoch 149: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0035 - val_mae: 0.0367\n",
      "Epoch 150/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0340\n",
      "Epoch 150: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0035 - val_mae: 0.0370\n",
      "Epoch 151/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0351\n",
      "Epoch 151: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0034 - val_mae: 0.0360\n",
      "Epoch 152/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0335\n",
      "Epoch 152: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0035 - val_mae: 0.0361\n",
      "Epoch 153/200\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0351\n",
      "Epoch 153: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0347 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 154/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0334\n",
      "Epoch 154: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0036 - val_mae: 0.0366\n",
      "Epoch 155/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0339\n",
      "Epoch 155: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0036 - val_mae: 0.0358\n",
      "Epoch 156/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0335\n",
      "Epoch 156: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0037 - val_mae: 0.0372\n",
      "Epoch 157/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0348\n",
      "Epoch 157: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0035 - val_mae: 0.0384\n",
      "Epoch 158/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0339\n",
      "Epoch 158: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0034 - val_mae: 0.0350\n",
      "Epoch 159/200\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0343\n",
      "Epoch 159: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0038 - val_mae: 0.0385\n",
      "Epoch 160/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0340\n",
      "Epoch 160: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0367\n",
      "Epoch 161/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0350\n",
      "Epoch 161: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0035 - val_mae: 0.0359\n",
      "Epoch 162/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 162: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0040 - val_mae: 0.0366\n",
      "Epoch 163/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0367\n",
      "Epoch 163: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0037 - val_mae: 0.0389\n",
      "Epoch 164/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0355\n",
      "Epoch 164: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.0037 - val_mae: 0.0349\n",
      "Epoch 165/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0333\n",
      "Epoch 165: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0035 - val_mae: 0.0373\n",
      "Epoch 166/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0342\n",
      "Epoch 166: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.0036 - val_mae: 0.0355\n",
      "Epoch 167/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0337\n",
      "Epoch 167: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0335 - val_loss: 0.0039 - val_mae: 0.0374\n",
      "Epoch 168/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0338\n",
      "Epoch 168: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0361\n",
      "Epoch 169/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344\n",
      "Epoch 169: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0037 - val_mae: 0.0359\n",
      "Epoch 170/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0350\n",
      "Epoch 170: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.0038 - val_mae: 0.0382\n",
      "Epoch 171/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341\n",
      "Epoch 171: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0040 - val_mae: 0.0392\n",
      "Epoch 172/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0343\n",
      "Epoch 172: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0037 - val_mae: 0.0379\n",
      "Epoch 173/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0343\n",
      "Epoch 173: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0036 - val_mae: 0.0359\n",
      "Epoch 174/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0348\n",
      "Epoch 174: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0036 - val_mae: 0.0353\n",
      "Epoch 175/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0339\n",
      "Epoch 175: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0038 - val_mae: 0.0369\n",
      "Epoch 176/200\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 176: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0035 - val_mae: 0.0348\n",
      "Epoch 177/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 177: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0036 - val_mae: 0.0361\n",
      "Epoch 178/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0329\n",
      "Epoch 178: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0036 - val_mae: 0.0364\n",
      "Epoch 179/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341\n",
      "Epoch 179: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0036 - val_mae: 0.0373\n",
      "Epoch 180/200\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0341\n",
      "Epoch 180: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0036 - val_mae: 0.0359\n",
      "Epoch 181/200\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0344\n",
      "Epoch 181: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0043 - val_mae: 0.0395\n",
      "Epoch 182/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0348\n",
      "Epoch 182: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0037 - val_mae: 0.0374\n",
      "Epoch 183/200\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0349\n",
      "Epoch 183: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0349 - val_loss: 0.0039 - val_mae: 0.0390\n",
      "Epoch 184/200\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0339\n",
      "Epoch 184: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0339 - val_loss: 0.0035 - val_mae: 0.0361\n",
      "Epoch 185/200\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0344\n",
      "Epoch 185: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0341 - val_loss: 0.0036 - val_mae: 0.0378\n",
      "Epoch 186/200\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0343\n",
      "Epoch 186: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0338 - val_loss: 0.0035 - val_mae: 0.0369\n",
      "Epoch 187/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0341\n",
      "Epoch 187: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0035 - val_mae: 0.0372\n",
      "Epoch 188/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344\n",
      "Epoch 188: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0356\n",
      "Epoch 189/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 189: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0351 - val_loss: 0.0037 - val_mae: 0.0386\n",
      "Epoch 190/200\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 190: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0035 - val_mae: 0.0344\n",
      "Epoch 191/200\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0335\n",
      "Epoch 191: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0036 - val_mae: 0.0361\n",
      "Epoch 192/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0340\n",
      "Epoch 192: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0036 - val_mae: 0.0367\n",
      "Epoch 193/200\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0321\n",
      "Epoch 193: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0036 - val_mae: 0.0371\n",
      "Epoch 194/200\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0346\n",
      "Epoch 194: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0036 - val_mae: 0.0373\n",
      "Epoch 195/200\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 195: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0337 - val_loss: 0.0037 - val_mae: 0.0370\n",
      "Epoch 196/200\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0339\n",
      "Epoch 196: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0036 - val_mae: 0.0378\n",
      "Epoch 197/200\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0331\n",
      "Epoch 197: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0037 - val_mae: 0.0367\n",
      "Epoch 198/200\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0342\n",
      "Epoch 198: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0035 - val_mae: 0.0375\n",
      "Epoch 199/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0337\n",
      "Epoch 199: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0037 - val_mae: 0.0370\n",
      "Epoch 200/200\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0346\n",
      "Epoch 200: val_loss did not improve from 0.00332\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0035 - val_mae: 0.0343\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cead2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_scaler.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "joblib.dump(x_scaler, 'x_scaler.joblib')\n",
    "joblib.dump(y_scaler, 'y_scaler.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
